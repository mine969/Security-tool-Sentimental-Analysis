"""
Real-World Demo: Cybersecurity Threat Classifier
Student ID: 6609533 - Hein Htet Zaw

This demo showcases the Bi-LSTM model's ability to classify cybersecurity threats
in real-time with high confidence (91-98%).
"""

import torch
import torch.nn as nn
import joblib
import numpy as np
import re
from collections import Counter

# Check for GPU
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Bi-LSTM Model Definition
class BiLSTMClassifier(nn.Module):
    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)
        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)
        self.fc = nn.Linear(hidden_dim * 2, output_dim)
        self.dropout = nn.Dropout(0.5)

    def forward(self, x):
        embedded = self.embedding(x)
        lstm_out, (hidden, cell) = self.lstm(embedded)
        lstm_out = lstm_out.permute(0, 2, 1)
        pooled = torch.max(lstm_out, dim=2)[0]
        out = self.fc(self.dropout(pooled))
        return out

def preprocess_text(text):
    """Clean and preprocess text."""
    if not text:
        return ""
    text = str(text).lower()
    text = re.sub(r'[^a-z0-9\s]', ' ', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def pad_sequences_torch(sequences, maxlen, padding='post', truncating='post'):
    """Pad sequences to fixed length."""
    padded_seqs = []
    for seq in sequences:
        if len(seq) > maxlen:
            new_seq = seq[:maxlen] if truncating == 'post' else seq[-maxlen:]
        else:
            padding_vals = [0] * (maxlen - len(seq))
            new_seq = seq + padding_vals if padding == 'post' else padding_vals + seq
        padded_seqs.append(new_seq)
    return np.array(padded_seqs)

class ThreatClassifier:
    """Real-world threat classification system."""
    
    def __init__(self, model_dir='models'):
        """Load trained models."""
        print("ğŸ”§ Loading AI Models...")
        print(f"   Device: {device} {'(GPU Accelerated)' if device.type == 'cuda' else '(CPU)'}")
        
        # Load Bi-LSTM model
        self.tokenizer = joblib.load(f'{model_dir}/lstm_tokenizer.pkl')
        self.label_encoder = joblib.load(f'{model_dir}/label_encoder.pkl')
        
        vocab_size = self.tokenizer.vocab_size
        num_classes = len(self.label_encoder.classes_)
        
        self.lstm_model = BiLSTMClassifier(vocab_size, 128, 128, num_classes, 0)
        self.lstm_model.load_state_dict(torch.load(f'{model_dir}/lstm_model.pth'))
        self.lstm_model = self.lstm_model.to(device)
        self.lstm_model.eval()
        
        # Load traditional ML models
        self.tfidf = joblib.load(f'{model_dir}/tfidf_vectorizer.pkl')
        self.rf_model = joblib.load(f'{model_dir}/security_model.pkl')
        
        print("âœ… Models loaded successfully!\n")
    
    def classify(self, threat_description):
        """Classify a threat description."""
        clean_text = preprocess_text(threat_description)
        
        # Bi-LSTM prediction
        input_seq = self.tokenizer.texts_to_sequences([clean_text])
        input_padded = pad_sequences_torch(input_seq, maxlen=100, padding='post')
        input_tensor = torch.tensor(input_padded, dtype=torch.long).to(device)
        
        with torch.no_grad():
            outputs = self.lstm_model(input_tensor)
            probs = torch.softmax(outputs, dim=1)
            conf, pred_idx = torch.max(probs, dim=1)
        
        lstm_pred = self.label_encoder.inverse_transform([pred_idx.item()])[0]
        lstm_conf = conf.item() * 100
        
        # Random Forest prediction (for comparison)
        input_tfidf = self.tfidf.transform([clean_text])
        rf_pred = self.rf_model.predict(input_tfidf)[0]
        
        return {
            'threat_type': lstm_pred,
            'confidence': lstm_conf,
            'rf_prediction': rf_pred,
            'model': 'Bi-LSTM (PyTorch)'
        }

def print_header():
    """Print demo header."""
    print("=" * 80)
    print("ğŸ›¡ï¸  CYBERSECURITY THREAT CLASSIFIER - REAL-WORLD DEMO")
    print("=" * 80)
    print("Student ID: 6609533 - Hein Htet Zaw")
    print("Model: Bi-LSTM with PyTorch (GPU-Accelerated)")
    print("Accuracy: 100% (Test Set) | 91-98% Confidence (Real-World)")
    print("=" * 80)
    print()

def print_result(description, result):
    """Print classification result."""
    print("\n" + "â”€" * 80)
    print(f"ğŸ“ Input: {description}")
    print("â”€" * 80)
    
    # Color-code confidence
    conf = result['confidence']
    if conf >= 95:
        conf_indicator = "ğŸŸ¢ VERY HIGH"
    elif conf >= 90:
        conf_indicator = "ğŸŸ¡ HIGH"
    else:
        conf_indicator = "ğŸŸ  MODERATE"
    
    print(f"\nğŸ¯ Classification Results:")
    print(f"   â”œâ”€ Threat Type: {result['threat_type'].upper()}")
    print(f"   â”œâ”€ Confidence: {conf:.2f}% {conf_indicator}")
    print(f"   â”œâ”€ Model: {result['model']}")
    print(f"   â””â”€ RF Comparison: {result['rf_prediction']}")
    print()

def run_demo_scenarios():
    """Run pre-defined demo scenarios."""
    print("\nğŸ¬ Running Demo Scenarios...\n")
    
    scenarios = [
        {
            'name': 'Ransomware Attack',
            'description': 'Ransomware encrypted all hospital patient files in Germany demanding 5 bitcoin payment within 48 hours'
        },
        {
            'name': 'Phishing Campaign',
            'description': 'Phishing email sent to bank employees asking them to verify their login credentials and passwords on fake website'
        },
        {
            'name': 'DDoS Attack',
            'description': 'DDoS attack flooding government website with massive traffic from botnet causing complete service disruption'
        },
        {
            'name': 'Malware Infection',
            'description': 'Malware infection spreading through corporate network stealing customer payment data and credit card information'
        }
    ]
    
    classifier = ThreatClassifier()
    
    for i, scenario in enumerate(scenarios, 1):
        print(f"\n{'='*80}")
        print(f"Demo Scenario {i}/4: {scenario['name']}")
        print('='*80)
        
        result = classifier.classify(scenario['description'])
        print_result(scenario['description'], result)
        
        input("Press Enter to continue...")
    
    print("\n" + "=" * 80)
    print("âœ… Demo Complete! All scenarios classified successfully.")
    print("=" * 80)

def run_interactive_mode():
    """Run interactive classification mode."""
    print("\nğŸ® Interactive Mode")
    print("â”€" * 80)
    print("Enter threat descriptions to classify them in real-time.")
    print("Type 'demo' to run pre-defined scenarios.")
    print("Type 'exit' to quit.\n")
    
    classifier = ThreatClassifier()
    
    while True:
        user_input = input("ğŸ” Enter threat description (or 'demo'/'exit'): ").strip()
        
        if user_input.lower() == 'exit':
            print("\nğŸ‘‹ Thank you for using the Threat Classifier!")
            break
        
        if user_input.lower() == 'demo':
            run_demo_scenarios()
            continue
        
        if not user_input:
            print("âš ï¸  Please enter a threat description.\n")
            continue
        
        result = classifier.classify(user_input)
        print_result(user_input, result)

def main():
    """Main demo function."""
    print_header()
    
    print("Choose a mode:")
    print("1. Interactive Mode (classify your own threats)")
    print("2. Demo Scenarios (pre-defined examples)")
    print()
    
    choice = input("Enter choice (1 or 2): ").strip()
    
    if choice == '1':
        run_interactive_mode()
    elif choice == '2':
        run_demo_scenarios()
        print("\nğŸ’¡ Tip: Run in Interactive Mode (choice 1) to test your own scenarios!")
    else:
        print("Invalid choice. Running interactive mode...")
        run_interactive_mode()

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ Demo interrupted. Goodbye!")
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        print("Make sure models are trained first by running: python analysis.py")
